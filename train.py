import torch
import deepinv
from torchvision import datasets, transforms
import tqdm
import time
import os
# å¯¼å…¥é…ç½®æ–‡ä»¶
from config import (
    device, dataset_name, large_model, batch_size, image_size, img_channels,
    num_classes, lr, epochs, timestep, get_output_model_path, get_transform,
    create_diffusion_params
)

# è®¾ç½®matplotlibå­—ä½“ä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
import matplotlib.pyplot as plt

# æ‰“å°è®¾å¤‡ä¿¡æ¯
print(f"ä½¿ç”¨è®¾å¤‡: {device}")
if torch.cuda.is_available():
    print(f"GPUåç§°: {torch.cuda.get_device_name(0)}")
    print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.2f} GB")

# è·å–è¾“å‡ºæ¨¡å‹åç§°
output_model_name = get_output_model_path()

# è·å–æ•°æ®å˜æ¢
transform = get_transform()

# åˆ›å»ºæ‰©æ•£å‚æ•°
diffusion_params = create_diffusion_params()
betas = diffusion_params['betas']
alphas = diffusion_params['alphas']
alphas_cumprod = diffusion_params['alphas_cumprod']
sqrt_alphas_cumprod = diffusion_params['sqrt_alphas_cumprod']
sqrt_one_minus_alphas_cumprod = diffusion_params['sqrt_one_minus_alphas_cumprod']



plt.rcParams["font.family"] = ["SimHei"]
plt.rcParams["axes.unicode_minus"] = False


if dataset_name=='CIFAR100':
    train_loader = torch.utils.data.DataLoader(
        datasets.CIFAR100('./data', train=True, download=True, transform=transform),
        batch_size=batch_size, shuffle=True)
if dataset_name=='CIFAR10':
    train_loader = torch.utils.data.DataLoader(
        datasets.CIFAR10('./data', train=True, download=True, transform=transform),
        batch_size=batch_size, shuffle=True)
if dataset_name=='MNIST':
    train_loader = torch.utils.data.DataLoader(
        datasets.MNIST('./data', train=True, download=True, transform=transform),
        batch_size=batch_size, shuffle=True)


from model import DiffUNet

import os

# åˆå§‹åŒ–æ¨¡å‹
model = DiffUNet(in_channels=img_channels, out_channels=img_channels, num_classes=num_classes,large_model=large_model).to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=lr)
mse = torch.nn.MSELoss()

# ç”¨äºå­˜å‚¨è®­ç»ƒå†å²
train_loss_history = []

# æ£€æŸ¥æ˜¯å¦å­˜åœ¨å·²ä¿å­˜çš„æ¨¡å‹
if os.path.exists(output_model_name):
    try:
        # åŠ è½½å·²ä¿å­˜çš„æ¨¡å‹æƒé‡
        checkpoint = torch.load(output_model_name)
        model.load_state_dict(checkpoint)
        print(f"âœ… æˆåŠŸåŠ è½½å·²ä¿å­˜çš„æ¨¡å‹ '{output_model_name}'ï¼Œå°†ç»§ç»­è®­ç»ƒ")
    except Exception as e:
        print(f"âš ï¸ åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
        print("ğŸ”„ å¼€å§‹æ–°çš„è®­ç»ƒ")
else:
    print(f"ğŸ” æœªæ‰¾åˆ°å·²ä¿å­˜çš„æ¨¡å‹ '{output_model_name}'ï¼Œå¼€å§‹æ–°çš„è®­ç»ƒ")

# å¼€å§‹è®­ç»ƒ
total_start_time = time.time()

for epoch in range(epochs):
    model.train()
    epoch_loss = 0.0
    epoch_start_time = time.time()

    # åˆ›å»ºæ‰¹æ¬¡çº§è¿›åº¦æ¡
    batch_progress = tqdm.tqdm(enumerate(train_loader),
                               total=len(train_loader),
                               desc=f"Epoch {epoch + 1}/{epochs}",
                               leave=False,
                               bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]")

    for batch_idx, (data, labels) in batch_progress:  # æ³¨æ„è¿™é‡Œç°åœ¨æ¥æ”¶dataå’Œlabels
        # è®¡ç®—æ‰¹æ¬¡å¼€å§‹æ—¶é—´
        batch_start_time = time.time()

        # å‡†å¤‡æ•°æ®å’Œç±»åˆ«æ ‡ç­¾
        imgs = data.to(device)
        labels = labels.to(device)  # å°†ç±»åˆ«æ ‡ç­¾ç§»è‡³è®¾å¤‡
        noise = torch.randn_like(imgs)
        t = torch.randint(0, timestep, (imgs.shape[0],), device=device)

        # å‰å‘æ‰©æ•£è¿‡ç¨‹
        noisy_imgs = sqrt_alphas_cumprod[t, None, None, None] * imgs + \
                     sqrt_one_minus_alphas_cumprod[t, None, None, None] * noise

        # æ¨¡å‹é¢„æµ‹ä¸æŸå¤±è®¡ç®— - ä¼ é€’ç±»åˆ«æ ‡ç­¾y
        optimizer.zero_grad()
        # å…³é”®ä¿®æ”¹ï¼šå°†ç±»åˆ«æ ‡ç­¾labelsä½œä¸ºyå‚æ•°ä¼ é€’ç»™æ¨¡å‹
        estimated_noise = model(noisy_imgs, t, y=labels, type_t="timestep")
        loss = mse(estimated_noise, noise)

        # åå‘ä¼ æ’­ä¸ä¼˜åŒ–
        loss.backward()
        optimizer.step()

        # ç´¯è®¡æŸå¤±
        epoch_loss += loss.item()

        # è®¡ç®—æ‰¹æ¬¡å¤„ç†æ—¶é—´å’Œæ¯ç§’æ ·æœ¬æ•°
        batch_time = time.time() - batch_start_time
        samples_per_second = imgs.shape[0] / batch_time if batch_time > 0 else 0

        # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
        current_lr = optimizer.param_groups[0]['lr']
        avg_batch_loss = epoch_loss / (batch_idx + 1)

        # å‡†å¤‡è¿›åº¦æ¡åç¼€ä¿¡æ¯
        postfix_info = {
            'loss': f'{loss.item():.6f}',
            'avg_loss': f'{avg_batch_loss:.6f}',
            'lr': f'{current_lr:.6f}',
            'samples/s': f'{samples_per_second:.1f}'
        }

        # å¦‚æœåœ¨GPUä¸Šè®­ç»ƒï¼Œæ·»åŠ GPUå†…å­˜ä½¿ç”¨ä¿¡æ¯
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.memory_allocated(0) / 1024 ** 2  # MB
            postfix_info['gpu_mem'] = f'{gpu_memory:.1f}MB'

        batch_progress.set_postfix(postfix_info)

    # è®¡ç®—æœ¬è½®epochçš„å¹³å‡æŸå¤±å’Œæ—¶é—´
    avg_epoch_loss = epoch_loss / len(train_loader)
    epoch_time = time.time() - epoch_start_time
    train_loss_history.append(avg_epoch_loss)

    # è®¡ç®—é¢„è®¡å‰©ä½™æ—¶é—´
    elapsed_time = time.time() - total_start_time
    avg_epoch_time = elapsed_time / (epoch + 1)
    remaining_time = avg_epoch_time * (epochs - epoch - 1)

    # æ‰“å°æœ¬è½®epochçš„è¯¦ç»†ä¿¡æ¯
    print(f"Epoch {epoch + 1}/{epochs} - å¹³å‡æŸå¤±: {avg_epoch_loss:.6f} - ç”¨æ—¶: {epoch_time:.2f}ç§’ - "
          f"é¢„è®¡å‰©ä½™: {remaining_time // 60:.0f}åˆ†{remaining_time % 60:.0f}ç§’")

    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), output_model_name)
print(f"è®­ç»ƒå®Œæˆï¼æ€»ç”¨æ—¶: {time.time() - total_start_time:.2f}ç§’")
print(f"æ¨¡å‹å·²ä¿å­˜ä¸º '{output_model_name}'")

# ç»˜åˆ¶è®­ç»ƒæŸå¤±æ›²çº¿
plt.figure(figsize=(10, 6))
plt.plot(range(1, epochs + 1), train_loss_history, '-b', label='è®­ç»ƒæŸå¤±')
plt.title('è®­ç»ƒæŸå¤±æ›²çº¿')
plt.xlabel('Epoch')
plt.ylabel('æŸå¤±å€¼')
plt.grid(True)
plt.legend()
plt.tight_layout()
# åˆ›å»ºä¿å­˜å›¾åƒçš„æ–‡ä»¶å¤¹
os.makedirs('./pic/train', exist_ok=True)
plt.savefig(f'./pic//train/{dataset_name}_{"large" if large_model else "small"}_diffusion_loss.png')
plt.close()
print(f"âœ… è®­ç»ƒæŸå¤±ç»“æœå·²ä¿å­˜åˆ° './pic/train/{dataset_name}_{"large" if large_model else "small"}_diffusion_loss.png'")



